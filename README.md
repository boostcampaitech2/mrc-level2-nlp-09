# KLUE Open-Domain Question Answering, Naver Boostcamp AI Tech 2ê¸°

## Competition Abstract

ğŸ¤“ KLUE MRC(Machine Reading Comprehension) Datasetìœ¼ë¡œ Open-Domain Question Answeringì„ ìˆ˜í–‰í•˜ëŠ” Task.  
ğŸ¤“ ì§ˆë¬¸ì— ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ì°¾ì•„ì£¼ëŠ” Retrieverì™€ ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ì½ê³  ë‹µë³€ì„ í•˜ëŠ” Readerë¡œ êµ¬ì„±.  
ğŸ¤“ Leaderboardì—ì„œ Public 240ê°œ, Private 360ê°œë¡œ í‰ê°€ê°€ ì´ë£¨ì–´ì§.  
ğŸ¤“ í•˜ë£¨ 10íšŒë¡œ ëª¨ë¸ ì œì¶œ ì œí•œ

## [Competition Report(PDF)](competition_results/nlp-p-p09_mrc.pdf)

## Our solutions

- retrieval
  - Elastic search
  - Pororo NER
- Data Augmentation
  - Negative Sampling
  - Question Generation
- Post Processing
  - Top-k Passages Seperate
  - Answer scoring with softmax
  - Similiarity scoring with KSS(Korean Sentence Spliter)
  - Other post-processing via Mecab
- Ensemble
  - Hard voting
  - Post processing

## ìµœì¢… ìˆœìœ„ 2ë“±!

<img src="competition_results/capture.png" width="80%">

---

## Installation

- python module: requirements.txt
- Elatsic Search: [Installation docs](https://www.elastic.co/guide/en/elasticsearch/reference/current/targz.html)
- Mecab: [Korean mecab doc](https://bitbucket.org/eunjeon/mecab-ko-dic/src/master/)

## Set environment

- Elastic Search
  - root userelastic_test.py
  ```
  python elastic_test.py
  ```
  - non-root user
  ```
  ./bin/elasticsearch -d -p pid
  ```
- Genertate NER tagged files

```
# outputs = train_tagged.csv, inference_tagged.csv
python make_ner_tag.py
```

- Generate K-fold trainig files

```
# outputs = fold{n}.csv
python make_ner_tag.py
```

- Indexing wikipedia files using Elastic search

```
python elastic_search.py
```

- wandb setting

```python
# default wandb setting in train.py
run = wandb.init(project= 'klue', entity= 'quarter100', name= f'Any training name')
```

- Copy qg_dataset in ../data directory

## Train model

```
python train.py
```

Models are saved in "./models/train_dataset\_{experiment_name}/".

## Inference

```
python inference.py --output_dir ./outputs/test_dataset/ --dataset_name ../data/test_dataset/ --model_name_or_path ./models/train_dataset/ --do_predict
```

Prediction csv files are saved in "./outputs/test_dataset/".

## Ensemble

- Hard voting
- Ensemble result is saved in "./submission_fold_total.csv".

## Docs

- [Question Generation](question_generation/README.md)

## Members

[ê¹€ë‹¤ì˜](https://github.com/keemdy), [ê¹€ë‹¤ì¸](https://github.com/danny980521), [ë°•ì„±í˜¸](https://github.com/naem1023), [ë°•ì¬í˜•](https://github.com/Jay-Ppark), [ì„œë™ê±´](https://github.com/donggunseo), [ì •ë¯¼ì§€](https://github.com/minji-o-j), [ìµœì„ë¯¼](https://github.com/RockMiin)

## Advisors

[ë°•ì±„í›ˆ ë©˜í† ë‹˜](https://github.com/ddehun)
